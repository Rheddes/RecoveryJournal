{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recsys-twitter-make-predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rheddes/RecoveryJournal/blob/master/recsys_twitter_make_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZn8mKIfxjK",
        "colab_type": "text"
      },
      "source": [
        "# Necessary imports & definitions\n",
        "\n",
        "Copy files from drive to local disk, not necessary it is also possible to work directly from drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEaruqpdxx8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7d57cf29-3277-43e8-92f2-4dd6fdeee6d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPK_jtcJwxpJ",
        "colab_type": "text"
      },
      "source": [
        "## Get validation set\n",
        "\n",
        "Get the validation/prediction set from the challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqMvNlDcTy-u",
        "colab_type": "text"
      },
      "source": [
        "Set train file variable to correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHeXqCv8Tmwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_file = './sample.tsv'\n",
        "# train_features_file = './bert_22500.csv'\n",
        "# pred_file = ./val.tsv\n",
        "\n",
        "# OR IF USING THE ONE FROM DRIVE\n",
        "train_file = './drive/My Drive/RecSys/sample.tsv'\n",
        "train_features_file = './drive/My Drive/RecSys/bert_22500.csv'\n",
        "pred_file = './drive/My Drive/RecSys/val.tsv'\n",
        "pred_features_file = './drive/My Drive/RecSys/bert_22500.csv' # CHANGE WITH ACTUAL FEATURE FILE OF VALIDATION SET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvX-aYUwTv8C",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVMsiUBbfw14",
        "colab_type": "code",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "import gc\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import islice\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7vmmxXpyQAx",
        "colab_type": "text"
      },
      "source": [
        "# Read dataset\n",
        "\n",
        "Read labels & features from csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV1sFnn-Q5aJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb0dfad6-dc41-4a78-96d4-82789f1bfff9"
      },
      "source": [
        "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
        "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
        "                \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\",\n",
        "                \"engaged_with_user_account_creation\", \"enaging_user_id\", \"enaging_user_follower_count\",\n",
        "                \"enaging_user_following_count\",\n",
        "                \"enaging_user_is_verified\", \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
        "label_names = [\"replied\", \"retweeted\", \"retweeted_with_comment\", \"liked\"]\n",
        "\n",
        "# IF FEATURES AS CSV\n",
        "features = pd.read_csv(train_features_file).values\n",
        "# IF FEATURES AS PICKLE OBJECT\n",
        "# features = pickle.load(open(feature_file, 'rb'))\n",
        "\n",
        "labels = pd.read_csv(train_file, header=None, sep=\"\\x01\")\n",
        "labels.columns = all_features + label_names\n",
        "labels = labels[['replied','retweeted', 'retweeted_with_comment', 'liked']]\n",
        "\n",
        "print(\"converting now\")\n",
        "\n",
        "for label_name in label_names:\n",
        "  labels[label_name] = labels[label_name].apply(lambda x: 0 if math.isnan(x) else 1)\n",
        "\n",
        "# IF NOT ALL SAMPLES HAVE BEEN CONVERTED TO BERT FEATURES\n",
        "labels = labels[:len(features)]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEdFcmYCUcbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSh9GbdqZD-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation = pd.read_csv(pred_file, header=None, sep=\"\\x01\")\n",
        "validation.columns = all_features\n",
        "\n",
        "# IF FEATURES AS CSV\n",
        "validation_features = pd.read_csv(pred_features_file).values\n",
        "# IF FEATURES AS PICKLE OBJECT\n",
        "# validation_features = pickle.load(open(pred_features_file, 'rb'))\n",
        "\n",
        "# IF NOT ALL ROWS HAVE FEATURES\n",
        "validation = validation[:len(validation_features)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imcgdtsaim5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "B_IVd-WIxtzN",
        "colab_type": "text"
      },
      "source": [
        "# Train model\n",
        "\n",
        "We got our output from the BERT model we can now train our logistics classifier to actually classify tweet engagements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg5aEJQ6bw1d",
        "colab_type": "text"
      },
      "source": [
        "## Dimensionality Reduction\n",
        "\n",
        "Maybe not needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC0iN1PcWqhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "\n",
        "use_pca = True\n",
        "\n",
        "if use_pca:\n",
        "  n_components = 20\n",
        "  ipca = IncrementalPCA(n_components=n_components, batch_size=150)\n",
        "  train_features = ipca.fit_transform(features)\n",
        "else:\n",
        "  train_features = features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neWbHo4c391S",
        "colab_type": "text"
      },
      "source": [
        "## Train Model on test features\n",
        "\n",
        "Next train our Logistics Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btnSZmZg4AFY",
        "colab_type": "code",
        "outputId": "50ba6b41-396d-4a55-e9ed-06f72e4e53fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "models = {}\n",
        "\n",
        "for label_name in label_names:\n",
        "  models[label_name] = LinearSVC(C=1.0)\n",
        "  models[label_name].fit(train_features, labels[label_name].values)\n",
        "\n",
        "print(models)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00  1.74062130e-01 -4.33971060e-02 ...  5.50689700e-01\n",
            "   1.86707590e-01 -1.98577990e-01]\n",
            " [ 1.00000000e+00 -1.19644050e-01 -2.67190340e-01 ...  3.06257670e-01\n",
            "   3.19380570e-02 -4.96699360e-02]\n",
            " [ 2.00000000e+00  1.01058975e-01 -1.48502190e-02 ...  2.96512500e-01\n",
            "   2.80769140e-01  3.42546960e-02]\n",
            " ...\n",
            " [ 2.24997000e+05 -2.54571470e-01  1.40958280e-01 ...  4.86173000e-01\n",
            "   4.11130560e-02 -9.20219900e-02]\n",
            " [ 2.24998000e+05 -9.26982400e-03 -1.80375170e-01 ...  2.18384500e-01\n",
            "   1.56419380e-01 -1.52135860e-01]\n",
            " [ 2.24999000e+05 -3.41064630e-01  4.65842400e-02 ...  3.48190160e-01\n",
            "   8.76392950e-02 -8.85488100e-02]]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[ 0.00000000e+00  1.74062130e-01 -4.33971060e-02 ...  5.50689700e-01\n",
            "   1.86707590e-01 -1.98577990e-01]\n",
            " [ 1.00000000e+00 -1.19644050e-01 -2.67190340e-01 ...  3.06257670e-01\n",
            "   3.19380570e-02 -4.96699360e-02]\n",
            " [ 2.00000000e+00  1.01058975e-01 -1.48502190e-02 ...  2.96512500e-01\n",
            "   2.80769140e-01  3.42546960e-02]\n",
            " ...\n",
            " [ 2.24997000e+05 -2.54571470e-01  1.40958280e-01 ...  4.86173000e-01\n",
            "   4.11130560e-02 -9.20219900e-02]\n",
            " [ 2.24998000e+05 -9.26982400e-03 -1.80375170e-01 ...  2.18384500e-01\n",
            "   1.56419380e-01 -1.52135860e-01]\n",
            " [ 2.24999000e+05 -3.41064630e-01  4.65842400e-02 ...  3.48190160e-01\n",
            "   8.76392950e-02 -8.85488100e-02]]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[ 0.00000000e+00  1.74062130e-01 -4.33971060e-02 ...  5.50689700e-01\n",
            "   1.86707590e-01 -1.98577990e-01]\n",
            " [ 1.00000000e+00 -1.19644050e-01 -2.67190340e-01 ...  3.06257670e-01\n",
            "   3.19380570e-02 -4.96699360e-02]\n",
            " [ 2.00000000e+00  1.01058975e-01 -1.48502190e-02 ...  2.96512500e-01\n",
            "   2.80769140e-01  3.42546960e-02]\n",
            " ...\n",
            " [ 2.24997000e+05 -2.54571470e-01  1.40958280e-01 ...  4.86173000e-01\n",
            "   4.11130560e-02 -9.20219900e-02]\n",
            " [ 2.24998000e+05 -9.26982400e-03 -1.80375170e-01 ...  2.18384500e-01\n",
            "   1.56419380e-01 -1.52135860e-01]\n",
            " [ 2.24999000e+05 -3.41064630e-01  4.65842400e-02 ...  3.48190160e-01\n",
            "   8.76392950e-02 -8.85488100e-02]]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[ 0.00000000e+00  1.74062130e-01 -4.33971060e-02 ...  5.50689700e-01\n",
            "   1.86707590e-01 -1.98577990e-01]\n",
            " [ 1.00000000e+00 -1.19644050e-01 -2.67190340e-01 ...  3.06257670e-01\n",
            "   3.19380570e-02 -4.96699360e-02]\n",
            " [ 2.00000000e+00  1.01058975e-01 -1.48502190e-02 ...  2.96512500e-01\n",
            "   2.80769140e-01  3.42546960e-02]\n",
            " ...\n",
            " [ 2.24997000e+05 -2.54571470e-01  1.40958280e-01 ...  4.86173000e-01\n",
            "   4.11130560e-02 -9.20219900e-02]\n",
            " [ 2.24998000e+05 -9.26982400e-03 -1.80375170e-01 ...  2.18384500e-01\n",
            "   1.56419380e-01 -1.52135860e-01]\n",
            " [ 2.24999000e+05 -3.41064630e-01  4.65842400e-02 ...  3.48190160e-01\n",
            "   8.76392950e-02 -8.85488100e-02]]\n",
            "[0 1 1 ... 1 1 0]\n",
            "{'replied': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'retweeted': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'retweeted_with_comment': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'liked': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYXa30iAJ1g7",
        "colab_type": "text"
      },
      "source": [
        "# Create predictions\n",
        "\n",
        "Now that we have a trained model, we can make predictions for the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H40-SVd4cYFI",
        "colab_type": "text"
      },
      "source": [
        "## If dimensionality reduction\n",
        "\n",
        "Perform PCA transform if dimensionality reduction was used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I8N-jHSYcgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_pca:\n",
        "  validation_features = ipca.transform(validation_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36oSG1f_chsl",
        "colab_type": "text"
      },
      "source": [
        "## Create Predictions\n",
        "\n",
        "Now we can actually generate predictions from our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTZukux0colG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for label_name, classifier in models.items():\n",
        "  predictions = classifier.predict(validation_features)\n",
        "  validation[label_name + '_prediction'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iITxxqkkdkca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir predictions\n",
        "\n",
        "for label_name in label_names:\n",
        "  prediction_column = label_name + '_prediction'\n",
        "  prediction = validation[['tweet_id', 'enaging_user_id', prediction_column]]\n",
        "  prediction.to_csv('./predictions/{}.csv'.format(prediction_column), header=None, index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7tUQAZpqQXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3bac86b6-fc89-41bd-af70-0de742543444"
      },
      "source": [
        "validation.retweeted_with_comment_prediction.value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    225000\n",
              "Name: retweeted_with_comment_prediction, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRRFmPyGkLY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "2cf3ed33-e10a-4c80-9f11-58caaa9ac615"
      },
      "source": [
        "i = 0\n",
        "with open('./predictions/replied_prediction.csv', encoding=\"utf-8\") as fileobject:\n",
        "    for line in fileobject:\n",
        "      print(line)\n",
        "      if i > 10:\n",
        "        break\n",
        "      i += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7647B4E9DAF4C1D8973397DC2A04F3E3,0000006C3074607050F1339DDCB890BB,0\n",
            "\n",
            "408DB1803264B5FF55F73EC06BE9BD77,000013315386492275CCBF7AEF293EF0,0\n",
            "\n",
            "2EE951379C47E8BF62EABB8FA027F753,00001569CB28972FC8173122D9DA162F,0\n",
            "\n",
            "2135F24B05DAE3EF213F9CE80FDC6DAF,00001607209C5774DF9207A2AC0EED5F,0\n",
            "\n",
            "09143FEDE9BD494A6EA9A7EE160565E3,0000177705514C315F2FC6DFA3872712,0\n",
            "\n",
            "60968762145D2AF58A58AFB376B2B00C,00001BC70532632181F17B2A65EFD2BA,0\n",
            "\n",
            "3487905D0C69B0FE4A6C7A301FB6F8BF,00001D9D15FBADE90ADE2577DC0C3593,0\n",
            "\n",
            "706310D7975C15B9FB1FA3FBAE8A126B,00001F56CDCF81D2EF635B3C0EDE57EB,0\n",
            "\n",
            "DBC37B8C8DC70C70F588D37CC5006ABB,00001F56CDCF81D2EF635B3C0EDE57EB,0\n",
            "\n",
            "BA7917AA4B620B13264A68F455203934,0000376314CAC0A3E9D4FCF4A29004D6,0\n",
            "\n",
            "60DD856C81BC0A115365FA556672C2DB,000043D9A730DF47697D0750F509B56A,0\n",
            "\n",
            "CFBD0716FB1FE99692156EC937E598B7,00004E42009644A7647E8C988C072D9D,0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}